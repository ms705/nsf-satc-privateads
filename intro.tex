\section{Introduction}
\label{s:overview}

%\subsection{Online Advertising}

Today's web ecosystem crucially relies on online advertising as a source of
revenue for web services that are free to end users.
%
Advertising is a trillion-dollar market, with Google---one of the key
players---seeing revenue upwards of \$140B in 2020 alone~\cite{google-ad-revenue}.
%

The ad market involves interaction between four types of mutually distrustful parties:
(1) the \textbf{advertiser}, who seeks to show ads to end users who
   are likely to engage with them (possibly spending money with the
   advertiser as a result), and who is willing to pay for users to view
   these ads;
 %
(2) the \textbf{publisher}, who operates a website that has an audience
   of users to whom advertisers might wish to advertise, and who seeks
   to monetize their content and audience by showing ads;
 %
 (3) the \textbf{platform} or ``ad network'', who connects advertisers
   to publishers who have users with the right interest, and takes a cut
   of the publishers' ad revenues; and
 %
 (4) the \textbf{end user}, who uses the publisher's website and generates
   behavioral data (which could be sensitive) used for ad targeting in doing so,
   who sees the platform's chosen advertiser's ads and potentially interacts
   with them.

The money flows from the advertisers to the platform for placing ads with publishers, so that they will ultimately be seen and acted upon by users.
%
The advertisers don't entirely trust the platforms to bill them correctly and need accounting mechanisms they can rely on and audit.
%
Similarly, the publishers do not entirely trust the platforms to accurately reward them for showing ads to visitors to their sites, and want trustworthy and auditable accounting mechanisms as well.
%
Well-known platforms include Google's and Meta's Ad business, as well
as Bing Ads, Criteo, Zedo, and others.
%
As a middle-man between advertisers, publishers, and end users, the platform
holds tremendous power and receives significant sensitive information, including
who viewed which ad and whether they interacted with it.
%
%
%
%However, users would prefer to avoid revealing their activity related to ads to the publisher and to the platform.

\textbf{
Our goal is to realize these mechanisms \emph{without any need for any of these parties to track the users}.} 
The research objective of this proposal is to design cryptographic protocols and
computer systems that improve data privacy in web advertising, today's
predominant business model for web services.
%
Our approach will, ideally, lead to technology that support today's advertising
ecosystem with much improved privacy for individual users who view and
interact with online advertisements.
%

\paragraph{Privacy desiderata.}
%
We would like to ensure that the user is not tracked by any participant; in particular, this means that even though the platform acts as a middleman and shows ads to this user, the platform does not know which user it is serving an ad to, or generally which user it is interacting with.
%
Publishers and advertisers don't learn anything about the user as a result of interacting with the ad system either; of course they may already know a lot about the user because the publisher often has an established relationship with them (for example, a news website may require log-in credentials from its subscribers) and the advertiser may learn the user's identity when the user makes a purchase; we only require that they not learn anything that they don't already know.
%
Additionally, we don't want the publisher to find out which ad the platform showed to the user next to the publisher's content, or the advertisers to find out which publishers sent them their customers---otherwise, they may choose to cut out the platform's services and the market won't work anymore.
%
Finally, we require that  neither publisher, nor advertiser or platform find out which \emph{specific} interaction (the combination of user identity, content viewed, and ad shown) results in a \emph{conversion} (a user making a purchase with the advertiser as a result of seeing an ad); they only learn that a real user, a real ad, and a real conversion event were involved.
%


\paragraph{Security and accountability desiderata.}
%
%Advertising involves money changing hands, and thus provides incentives for
%fraud.
%
In the online ad ecosystem's threat model, individual parties seek to maximize
their own revenue or minimize their costs, and of course there are incentives for fraud.
%
Collusion between parties can happen (\eg a publisher may create sybil end
users), and is common.
%

%
%The most important challenge is \textbf{click fraud}, which describes the idea
%of creating fake ad impressions and engagements in order to extract revenue from
%an advertiser.
%
%In particular, a publisher gains financially from showing more ads and from
%showing higher-value ads.
%
In the \emph{pay-per-click} ad revenue model, malicious publishers might generate fake traffic via sybil users (e.g., ``click
farms''~\cite{understanding-ad-fraud}), or misrepresent the real users' interest
towards the platform in order to get given more valuable ads.
%
One popular way to combat click fraud is for the platform to identify users,
collect their information, and monitor their behavior at scale, so as to be able to tell legitimate users apart from sybils.
%
But this user tracking approach is of course diametrically opposed to the users' justified desire for online
privacy.
%
Thus, a privacy-preserving way of preventing sybils is a desirable alternative to this approach.
%

%
The \emph{pay-per-conversion} ad revenue model, in which a publisher is rewarded only for ads that led end users to do something advertisers value (such as complete a purchase), leads to an even more sinister (from the privacy point of view) approach to tracking.
%
An ad puts a cookie in the user's browser; when the user later visits a relevant site, it scans all the cookies for those relevant to its ad campaigns, thereby discovering which ad(s) caused the user to visit the site.
%
These cookies are so damaging to consumer privacy that a push to remove the support for these so-called ``third-party" cookies has been successful~\cite{consumerreports-3rd-party-cookies}.
%
Of course, the beneficiaries of this success are large platforms that do not need cookies to track users' activities, and can therefore benefit from the demise of smaller ad networks.
%
Unless a privacy-friendly way to handle the ad economy can be found, these platforms will have an ever-greater incentive to track user activities.
%

%
Finally, in addition to preventing malicious behavior such as click fraud, ad ecosystems need to have mechanisms that ensure that advertisers reward publishers and platforms for serving successful ads.  
%

\paragraph{Threat model.}
%
We assume that publishers and advertisers trust the platform to be honest-but-curious (\ie faithfully execute our protocol). 
%
This is a reasonable assumption because both publishers and advertisers have a relationship with the platform, and thus may request access to third-party audits of the platform's business practices before contracting with it.  
%
We also assume that the platform trusts the client-side browser software to behave correctly.
%
Major ad platforms (\eg Google) in some cases also control browser software; however, since web browsers are open-source software, client-side modification is a possibility; but it is unlikely that a large number of end users will opt for it.
%
In any event, we assume that the ad platform can attest to the browser's integrity using technical means for remote attestation, such as a Trusted Platform Module (TPM).
%
When it encounters an unknown browser, the platform treats it as suspicious (\ie it might be a click farm) and excludes it from the ecosystem.
%

\paragraph{Our vision for reconciling privacy with accountability.}
%
In the proposed research, we will investigate an alternative to today's privacy-invasive
advertising ecosystem.
%
Our design, described in detail in \S\ref{s:design}, centers around a set of cryptographic tokens that different parties in the advertising ecosystem use to prove legitimate interactions to each other.
%
For example, when a user clicks on an ad, their browser sends the advertiser a token.  If this token is valid under the platform's public key the advertiser is assured that the user visiting them is a legitimate user and not a sybil created by a click farm.
%
For unforgeability, these tokens need to be signed; but for privacy, they should avoid carrying identifying information about the party that created or signed them.
%
We leverage prior and ongoing work on cryptographic \emph{blind signatures} to achieve this property.
%

%
Our approach draws on cryptographic tools and some minor changes to software, particular end-user browsers.
%
We also assume, for simplicity, that the end-user browser is trusted and that the platform has a means of validating that the end-user is running trusted, unmodified browser.
%

%\subsection{Towards Realizing Our Vision}
%
%We plan to tackle the problem of privacy-first advertising in two broad steps.
%
%first, we establish the primitives needed to carry out financial accounting in
%the ad ecosystem without requiring privacy-invasive data
%collection (\S\ref{r:fraud}), and then we 
%hide users' interests and behavior from the other parties in the ecosystem
%(\S\ref{r:matching}).
%


\subsection{Related Work}
\label{s:bg-related}
%
Privacy-preserving advertising has recently seen interest by researchers and industry practitioners.
%
However, existing solutions only address some of the privacy goals we seek to meet, or focus on the (equally important, but orthogonal) problem of targeting ads to users in a privacy-preserving manner, \ie without the platform needing to know the user's exact interests.
%
We describe key related work in the following; to our knowledge, our design would be the first to achieve strong end-to-end privacy guarantees between all participants (end-user, platform, publisher, and advertiser).
%

\paragraph{End-user privacy \vs the platform.}
%
Perhaps most related to our proposal is PrivAd~\cite{privad}, which introduces
an untrusted, anonymizing proxy between the end-user client and the platform.
%
This ``dealer'' mediates all interactions and mixes requests from different
end-user clients before a ``broker'' matches ads to the client.
%
The responsibility for click fraud detection lies with the broker and PrivAd
merely blocks clients flagged as suspicious.
%
PrivAd achieves high scalability and practical performance, as it only requires
symmetric-key cryptography and hashing on the critical path.
%
Unlike PrivAd, our design avoids the need for a dealer to mediate every
interaction, is based on blind signatures as a key cryptographic primitive,
and more closely matches the design and business processes of today's
ad ecosystem.
%

%
ObliviAd~\cite{obliviad} relies on hardware-based private information retrieval
(PIR) for ad distribution and mixing of billing tokens to establish client
privacy versus the platform.
%
PIR is a very expensive technique that is hard to scale; our work instead relies
on blind signatures, which can be implemented much more efficiently.
%

%
Adnostic~\cite{adnostic} proposes a browser-based user profiling
solution that moves the ad targeting into the user's browser and hides the
specific ad choice from the platform, but provides a cryptographic protocol for
billing the correct advertisers.
%
Green et al.~\cite{adnostic+} improved scale over Adnostic's protocol.
%
These techniques are complementary to our design, and could help us hide the
ad chosen from the platform.
%
Likewise, Google's Federated Learning of Cohorts (FLoC)~\cite{google-floc} and
related proposals~\cite{google-topic-based} track user interests
on the client side, and builds cohorts of users with similar interests.
%
The actual user interests and the browsing history the are inferred from remain
on the end-user device; the platform only finds out that a user has specific
interests, not their detailed browsing history.
%
The platform then targets ads to cohorts of users with these interests rather
than individuals.
%
Ibex~\cite{ibex} builds on these ideas and further reduces the information the platform
and advertiser gain.
%
Rather than revealing individual user preferences, Ibex has user browsers send
ciphertexts and computes over them for ad auctions and ad effectiveness tracking,
revealing only aggregate histograms to the platform and advertisers.
%
This work is orthogonal to our proposal: we assume that the platform has a way
of targeting ads to user interests, and a privacy-preserving way of realizing this
targeting of ads to users would strengthen our design without obviating the need for it.
%

\paragraph{Trust in the platform and advertisers.}
%
Pri-RTB~\cite{pri-rtb} is a private real-time-bidding (RTB) protocol for a
semi-honest setting, based on additively homomorphic encryption of user interest
profiles.
%
It seeks to hide user identities from advertisers, and trusts the
auctioneer (the platform) to run the computation correctly.
%
Our design also assumes that the platform correctly executes the ad matching process,
and provides anonymity of end users towards the advertiser, unless they choose to
reveal themselves through a conversion event.
%
%
In addition, our design also provides end-user privacy towards the platform, and privacy
guarantees between the publisher and the advertiser.
%
However, ad platforms are very powerful, and have incentives to potentially misbehave.
%
Some systems address the question of how to increase the publisher's and the advertiser's
trust that the platform is behaving honestly, checking, \eg that the platform tells the
truth about the price that the winning advertiser is willing to pay (rather than artifically
inflating this number).
%
Based on techniques such as verifiable actions and secure multi-party computation, Addax~\cite{addax} implements a trustworthy, anonymous auction protocol that keeps advertisers anonymous towards the platform while also guaranteeing correct behavior on the platform's part.
%
This is complementary to our proposed design: we assume an honest-but-curious platform, but seek to provide anonymity guarantees to end-users and between the publisher and the platform.
%
We assume that the platform has a way to match ads to end-users, but stop short of prescribing how this works; Addax's auctions (though expensive) are one possible realization of a privacy-preserving distributed RTB auction that could be fruitfully combined with our work.
%
%

%\paragraph{Click fraud prevention.}
%
%\todo{Add some references}
%
